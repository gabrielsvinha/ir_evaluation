{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/gabrielvinha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gabrielvinha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "import heapq\n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "\n",
    "data_url=\"./results.csv\"\n",
    "data = pd.read_csv(data_url).replace(np.nan, '', regex=True)\n",
    "documents = data.text.count()\n",
    "N = documents\n",
    "\n",
    "def parse(text):\n",
    "    words = []\n",
    "    word_pattern = rpt(r'\\w+')\n",
    "    year_pattern = rpt(r'\\d{4}')\n",
    "    \n",
    "    patterns = [word_pattern, year_pattern]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(text):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)\n",
    "    return words\n",
    "\n",
    "\n",
    "def build_index(dataset):\n",
    "    document_index = 0\n",
    "    index = {}\n",
    "    M = len(dataset.text)\n",
    "    for entry in dataset.text:\n",
    "        document_index = document_index + 1\n",
    "            \n",
    "        for ngram in parse(entry):\n",
    "            \n",
    "            if ngram in index:\n",
    "                if document_index in index[ngram]:\n",
    "                    index[ngram][document_index] = index[ngram][document_index] + 1\n",
    "                else:\n",
    "                    index[ngram][document_index] = 1 \n",
    "            else:\n",
    "                index[ngram] = {document_index: 1}\n",
    "                \n",
    "    for i in index:\n",
    "        k = len(index[i])\n",
    "        index[i][\"idf\"] = math.log10((M + 1) / k)\n",
    "    return index\n",
    "                        \n",
    "index = build_index(data)\n",
    "\n",
    "def bin_query_vector(index, query):\n",
    "    query_vector = []\n",
    "    \n",
    "    for word in index:\n",
    "        if word in query.split():\n",
    "            query_vector.append(True)\n",
    "        else:\n",
    "            query_vector.append(False)\n",
    "            \n",
    "    return query_vector\n",
    "\n",
    "def bin_document_vector(index):\n",
    "    document_vector = []\n",
    "    \n",
    "    for doc_id in range(1,documents+1):\n",
    "        doc_vec = []\n",
    "        for ngram in index:\n",
    "            if doc_id in index[ngram].keys():\n",
    "                doc_vec.append(True)\n",
    "            else:\n",
    "                doc_vec.append(False)\n",
    "                \n",
    "        document_vector.append(doc_vec)\n",
    "    \n",
    "    return document_vector\n",
    "                \n",
    "\n",
    "def f_bin(query_vector, doc_vector):\n",
    "    rec = {}\n",
    "\n",
    "    for doc_id in range(len(doc_vector)):\n",
    "        sim = 0\n",
    "        vector = doc_vector[doc_id]\n",
    "        for i in range(len(vector)):\n",
    "            sim += (query_vector[i] * vector[i])\n",
    "        rec[doc_id+1] = sim\n",
    "    \n",
    "    return rec\n",
    "\n",
    "def binary_vsm(index, query):\n",
    "    query_vector = bin_query_vector(index, query)   \n",
    "    doc_vector = bin_document_vector(index)\n",
    "    \n",
    "    return f_bin(query_vector, doc_vector)\n",
    "\n",
    "def get_top10rank(score):\n",
    "   \n",
    "    df_tmp = pd.DataFrame(score.items(), columns=[\"document\", \"score\"])\n",
    "    df_tmp['r']= df_tmp.score.rank(ascending=False, method=\"first\")\n",
    "    df_tmp.sort_values(\"r\", inplace = True)\n",
    "    df_tmp = df_tmp[:10]\n",
    "        \n",
    "    return df_tmp\n",
    "\n",
    "def tf_document_vector(index):\n",
    "    document_vector = []\n",
    "    \n",
    "    for doc_id in range(1,documents+1):\n",
    "        doc_vec = []\n",
    "        for ngram in index:\n",
    "            if doc_id in index[ngram].keys():\n",
    "                y = index[ngram][doc_id]\n",
    "                doc_vec.append(y)\n",
    "            else:\n",
    "                doc_vec.append(0)\n",
    "                \n",
    "        document_vector.append(doc_vec)\n",
    "        \n",
    "    return document_vector\n",
    "\n",
    "def tf_query_vector(index, query):\n",
    "    query_vector = []\n",
    "    \n",
    "    for ngram in index:\n",
    "        w = 0\n",
    "        for term in query.split():\n",
    "            if ngram == term:\n",
    "                w += 1\n",
    "        query_vector.append(w)\n",
    "        \n",
    "    return query_vector\n",
    "\n",
    "def f_tf(query_vector, doc_vector):\n",
    "    rec = {}\n",
    "    for doc_id in range(len(doc_vector)):\n",
    "        sim = 0\n",
    "        vector = doc_vector[doc_id]\n",
    "        for i in range(len(vector)):\n",
    "            sim += (query_vector[i] * vector[i])\n",
    "        rec[doc_id+1] = sim\n",
    "    return rec\n",
    "\n",
    "def tf_vsm(index, query):\n",
    "    query_vector = tf_query_vector(index, query)   \n",
    "    doc_vector = tf_document_vector(index)\n",
    "    \n",
    "    return f_tf(query_vector, doc_vector)\n",
    "\n",
    "def tfidf_document_vector(index):\n",
    "    document_vector = []\n",
    "    \n",
    "    for doc_id in range(1,documents+1):\n",
    "        doc_vec = []\n",
    "        for ngram in index:\n",
    "            if doc_id in index[ngram].keys():\n",
    "                y = index[ngram][doc_id] * index[ngram]['idf']\n",
    "                doc_vec.append(y)\n",
    "            else:\n",
    "                doc_vec.append(0)\n",
    "                \n",
    "        document_vector.append(doc_vec)\n",
    "        \n",
    "    return document_vector\n",
    "\n",
    "\n",
    "def tfidf_vsm(index, query):\n",
    "    query_vector = tf_query_vector(index, query)   \n",
    "    doc_vector = tfidf_document_vector(index)\n",
    "    \n",
    "    return f_tf(query_vector, doc_vector)\n",
    "\n",
    "def f_bm25(query_vector, doc_vector, k):\n",
    "    rec = {}\n",
    "    for doc_id in range(len(doc_vector)):\n",
    "        sim = 0\n",
    "        vector = doc_vector[doc_id]\n",
    "        for i in range(len(vector)):\n",
    "            if vector[i] != 0:\n",
    "                y = (k+1) * query_vector[i]\n",
    "                dom = (query_vector[i] * y)/(query_vector[i]+k)\n",
    "                sim += (dom * math.log10((documents + 1)/vector[i]))\n",
    "        rec[doc_id+1] = sim\n",
    "    return rec\n",
    "    \n",
    "\n",
    "def bm25_vsm(index, query, k):\n",
    "    query_vector = tf_query_vector(index, query)   \n",
    "    doc_vector = tf_document_vector(index)\n",
    "    \n",
    "    return f_bm25(query_vector, doc_vector, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document  score     r\n",
      "       13      2   1.0\n",
      "        4      1   2.0\n",
      "       63      1   3.0\n",
      "       65      1   4.0\n",
      "      157      1   5.0\n",
      "      182      1   6.0\n",
      "      184      1   7.0\n",
      "      188      1   8.0\n",
      "        1      0   9.0\n",
      "        2      0  10.0\n",
      "Rank: 1.0\n"
     ]
    }
   ],
   "source": [
    "chosen_one = 13\n",
    "doc_url = \"https://brasil.elpais.com/brasil/2019/03/15/cultura/1552681746_926411.html\"\n",
    "query = \"Gabo colombiano solid√£o\"\n",
    "\n",
    "def reciprocal_rank(rank, selected_doc):\n",
    "    position = 0\n",
    "    for index, row in rank.iterrows():\n",
    "        position += 1\n",
    "        if row[\"document\"] == chosen_one:\n",
    "            return 1.0/position\n",
    "     \n",
    "rank_binario = get_top10rank(binary_vsm(index, query))\n",
    "print(rank_binario.to_string(index=False))\n",
    "print(\"Rank:\", reciprocal_rank(rank_binario, chosen_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document  score     r\n",
      "       13      4   1.0\n",
      "       63      2   2.0\n",
      "        4      1   3.0\n",
      "       65      1   4.0\n",
      "      157      1   5.0\n",
      "      182      1   6.0\n",
      "      184      1   7.0\n",
      "      188      1   8.0\n",
      "        1      0   9.0\n",
      "        2      0  10.0\n",
      "Rank: 1.0\n"
     ]
    }
   ],
   "source": [
    "rank_tf = get_top10rank(tf_vsm(index, query))\n",
    "print(rank_tf.to_string(index=False))\n",
    "print(\"Rank:\", reciprocal_rank(rank_tf, chosen_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document     score     r\n",
      "       13  8.086610   1.0\n",
      "       63  3.591760   2.0\n",
      "        4  2.096910   3.0\n",
      "      157  1.920819   4.0\n",
      "      182  1.920819   5.0\n",
      "      184  1.920819   6.0\n",
      "       65  1.795880   7.0\n",
      "      188  1.795880   8.0\n",
      "        1  0.000000   9.0\n",
      "        2  0.000000  10.0\n",
      "Rank: 1.0\n"
     ]
    }
   ],
   "source": [
    "rank_tfidf = get_top10rank(tfidf_vsm(index, query))\n",
    "print(rank_tfidf.to_string(index=False))\n",
    "print(\"Rank:\", reciprocal_rank(rank_tfidf, chosen_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document     score     r\n",
      "       13  4.318759   1.0\n",
      "        4  2.397940   2.0\n",
      "       65  2.397940   3.0\n",
      "      157  2.397940   4.0\n",
      "      182  2.397940   5.0\n",
      "      184  2.397940   6.0\n",
      "      188  2.397940   7.0\n",
      "       63  2.096910   8.0\n",
      "        1  0.000000   9.0\n",
      "        2  0.000000  10.0\n",
      "Rank: 1.0\n"
     ]
    }
   ],
   "source": [
    "rank_bm25 = get_top10rank(bm25_vsm(index, query, 10))\n",
    "print(rank_bm25.to_string(index=False))\n",
    "print(\"Rank:\", reciprocal_rank(rank_bm25, chosen_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document  score     r\n",
      "        1      2   1.0\n",
      "        2      2   2.0\n",
      "        3      2   3.0\n",
      "       25      2   4.0\n",
      "       83      2   5.0\n",
      "       99      2   6.0\n",
      "      114      2   7.0\n",
      "      120      2   8.0\n",
      "      151      2   9.0\n",
      "      165      2  10.0\n",
      "MAP: 0.5625\n"
     ]
    }
   ],
   "source": [
    "query = \"golpe militar\"\n",
    "gabarito = [1, 120, 208]\n",
    "\n",
    "def map_ri(rank, relevant_docs):\n",
    "    relevant_documents = 0\n",
    "    position = 0\n",
    "    tmp_rank = 0.0\n",
    "    for index, row in rank.iterrows():\n",
    "        position += 1\n",
    "        if row[\"document\"] in relevant_docs:\n",
    "                relevant_documents += 1\n",
    "                tmp_rank += 1.0/position\n",
    "            \n",
    "    return tmp_rank/relevant_documents\n",
    "\n",
    "rank_binario = get_top10rank(binary_vsm(index, query))\n",
    "print(rank_binario.to_string(index=False))\n",
    "print(\"MAP:\", map_ri(rank_binario, gabarito))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document  score     r       DCG\n",
      "        1      2   1.0  6.000000\n",
      "        2      2   2.0  0.000000\n",
      "        3      2   3.0  0.000000\n",
      "       25      2   4.0  0.000000\n",
      "       83      2   5.0  0.000000\n",
      "       99      2   6.0  0.000000\n",
      "      114      2   7.0  0.000000\n",
      "      120      2   8.0  9.965784\n",
      "      151      2   9.0  0.000000\n",
      "      165      2  10.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "query = \"golpe militar\"\n",
    "### id dos documentos no gabarito da query\n",
    "gabarito = {1:6, 120:9, 208:5}\n",
    "\n",
    "def dcg(rank, relevant_docs):\n",
    "    relevant_documents = 0\n",
    "    position = 0\n",
    "    dcg_rank = []\n",
    "    for index, row in rank.iterrows():\n",
    "        position += 1\n",
    "        tmp_rank = 0.0\n",
    "        for d_id, rel in gabarito.items():\n",
    "            if d_id == row[\"document\"]:\n",
    "                if relevant_documents == 0:\n",
    "                    tmp_rank = rel\n",
    "                else:\n",
    "                    tmp_rank += (rel/math.log10(position))\n",
    "                relevant_documents += 1\n",
    "        dcg_rank.append(tmp_rank)\n",
    "                    \n",
    "            \n",
    "    return dcg_rank\n",
    "\n",
    "rank_binario = get_top10rank(binary_vsm(index, query))\n",
    "rank_binario[\"DCG\"] = dcg(rank_binario, gabarito)\n",
    "print(rank_binario.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document  score     r       DCG\n",
      "       25     23   1.0  0.000000\n",
      "        3     15   2.0  0.000000\n",
      "      208     12   3.0  5.000000\n",
      "      115      9   4.0  0.000000\n",
      "        7      8   5.0  0.000000\n",
      "      165      8   6.0  0.000000\n",
      "      223      8   7.0  0.000000\n",
      "        1      7   8.0  6.643856\n",
      "      166      7   9.0  0.000000\n",
      "      216      7  10.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "rank_tf = get_top10rank(tf_vsm(index, query))\n",
    "rank_tf[\"DCG\"] = dcg(rank_tf, gabarito)\n",
    "print(rank_tf.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document      score     r       DCG\n",
      "       25  20.980147   1.0  0.000000\n",
      "        3  13.195359   2.0  0.000000\n",
      "      208  10.688157   3.0  5.000000\n",
      "      165   7.455113   4.0  0.000000\n",
      "      166   7.058946   5.0  0.000000\n",
      "      223   6.795763   6.0  0.000000\n",
      "      115   6.532579   7.0  0.000000\n",
      "        1   6.399596   8.0  6.643856\n",
      "      230   6.399596   9.0  0.000000\n",
      "      216   6.069921  10.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "rank_tfidf = get_top10rank(tfidf_vsm(index, query))\n",
    "rank_tfidf[\"DCG\"] = dcg(rank_tfidf, gabarito)\n",
    "print(rank_tfidf.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " document     score     r  DCG\n",
      "      228  4.795880   1.0  0.0\n",
      "        2  4.494850   2.0  0.0\n",
      "       99  4.494850   3.0  0.0\n",
      "      114  4.494850   4.0  0.0\n",
      "      169  4.494850   5.0  0.0\n",
      "      120  4.318759   6.0  9.0\n",
      "      233  4.318759   7.0  0.0\n",
      "       83  4.193820   8.0  0.0\n",
      "      151  4.096910   9.0  0.0\n",
      "      166  4.017729  10.0  0.0\n"
     ]
    }
   ],
   "source": [
    "rank_bm25 = get_top10rank(bm25_vsm(index, query, 10))\n",
    "rank_bm25[\"DCG\"] = dcg(rank_bm25, gabarito)\n",
    "print(rank_bm25.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
